{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GabrielVeloso077/AutoMLAgents/blob/main/LangChain_RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "<table style=\"margin: auto; background-color: white;\">\n",
        "    <tr>\n",
        "      <td style=\"background-color: white;\">\n",
        "        <img src='https://drive.google.com/uc?export=view&id=1lgflViz1uefcvVW1iI57haB4M1bKsZtp' alt=\"drawing\" width=\"200\" />\n",
        "      </td>\n",
        "      <td style=\"background-color: white;\">\n",
        "        <img src='https://drive.google.com/uc?export=view&id=1S3xpVbkzpBAG51PyuRyIioecvZiHGSap' alt=\"drawing\" width=\"200\" />\n",
        "      </td>\n",
        "      <td style=\"background-color: white;\">\n",
        "        <img src='https://drive.google.com/uc?export=view&id=1lgflViz1uefcvVW1iI57haB4M1bKsZtp' alt=\"drawing\" width=\"200\" />\n",
        "      </td>\n",
        "      <td style=\"background-color: white;\">\n",
        "        <img src='https://drive.google.com/uc?export=view&id=1S3xpVbkzpBAG51PyuRyIioecvZiHGSap' alt=\"drawing\" width=\"200\" />\n",
        "      </td>\n",
        "      <td style=\"background-color: white;\">\n",
        "        <img src='https://drive.google.com/uc?export=view&id=1lgflViz1uefcvVW1iI57haB4M1bKsZtp' alt=\"drawing\" width=\"200\" />\n",
        "      </td>\n",
        "      <td style=\"background-color: white;\">\n",
        "        <img src='https://drive.google.com/uc?export=view&id=1S3xpVbkzpBAG51PyuRyIioecvZiHGSap' alt=\"drawing\" width=\"200\" />\n",
        "      </td>\n",
        "    </tr>\n",
        "</table>\n",
        "<font face=\"Verdana\" size=1 color='#707bf8' font-family= 'Alike Angular'> *Este material foi desenvolvido como parte do Projeto de Pesquisa em Parceria com a KUNUMI S/A <font>\n"
      ],
      "metadata": {
        "id": "c-1E9xStNhZh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font face=\"Rage\" size=7 color='#707bf8'> LangChain: RAG <font>\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6EPTm1oHUAsy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Instalação LangChain"
      ],
      "metadata": {
        "id": "B0_E0uDZp6S_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G3NwJxuco_7-"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet langchain\n",
        "!pip install --quiet langchain-community"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.chat_models import ChatDeepInfra\n",
        "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage"
      ],
      "metadata": {
        "id": "aHyvyS1ftd92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Acesso à plataforma DeepInfra"
      ],
      "metadata": {
        "id": "fYMjBzL-hzm0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "os.environ[\"DEEPINFRA_API_TOKEN\"] = getpass(\"Digite sua chave da DeepInfra: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7SjFdoEArAAb",
        "outputId": "97883d83-3478-4d83-adda-962a6ff6c8d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Digite sua chave da DeepInfra: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Geração aumentada por recuperação (RAG)\n",
        "\n",
        "Uma das aplicações mais poderosas possibilitadas pelos LLMs são os sofisticados chatbots de perguntas e respostas. São aplicativos que podem responder a perguntas sobre informações de fontes específicas. Esses aplicativos utilizam uma técnica conhecida como Geração Aumentada de Recuperação, ou RAG.\n",
        "\n",
        "Uma aplicação RAG típica tem os seguintes passos:\n",
        "\n",
        "\n",
        "\n",
        "1. **Carregar:** Primeiro, precisamos carregar nossos dados. Isso é feito com os Document Loaders.\n",
        "2. **Dividir:** Text splitters dividem grandes documentos em pedaços (chunks) menores. Isso é útil tanto para indexar dados quanto para passá-los para um modelo, pois chunks grandes são mais difíceis de pesquisar e não cabem na janela de contexto finita de um modelo.\n",
        "3. **Armazenamento:** Precisamos de um lugar para armazenar e indexar nossas divisões, para que possam ser pesquisadas posteriormente. Isso geralmente é feito usando um VectorStore e modelos Embeddings.\n",
        "4. **Recuperar:** Dada uma entrada do usuário, as divisões relevantes são recuperadas do armazenamento usando um Retriever.\n",
        "5. **Gerar:** Um ChatModel produz uma resposta usando um prompt que inclui a pergunta com os dados recuperados.\n",
        "\n"
      ],
      "metadata": {
        "id": "_qsaAqhmj7D5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1. Carregar\n",
        "\n",
        "Carregamento de um arquivo PDF."
      ],
      "metadata": {
        "id": "KT_R95B47nux"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pypdf"
      ],
      "metadata": {
        "id": "OXhqeUQ_RkMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders.pdf import PyPDFLoader\n",
        "\n",
        "arquivo = \"https://www2.camara.leg.br/legin/fed/lei/1990/lei-8069-13-julho-1990-372211-normaatualizada-pl.pdf\"\n",
        "loader = PyPDFLoader(arquivo)\n",
        "doc_pdf = loader.load()\n",
        "\n",
        "print(f'Número de páginas do PDF: {len(doc_pdf)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wcUSAtS0KTR",
        "outputId": "725120d3-b6e2-4cd3-99f7-2c0c2f035298"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de páginas do PDF: 72\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Carregamento de um arquivo CSV"
      ],
      "metadata": {
        "id": "f4AA61wB_oUo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
        "\n",
        "arquivo = \"imdb_movies.csv\"  # Faça apload de um arquivo CSV para testar\n",
        "loader = CSVLoader(arquivo)\n",
        "doc_csv = loader.load()\n",
        "\n",
        "print(f'Número de linhas do CSV: {len(doc_csv)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDjLmmEX_q8t",
        "outputId": "b93f62e2-61d6-47c6-ed18-5feb5340d745"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de linhas do CSV: 1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Carregamento via URL"
      ],
      "metadata": {
        "id": "1592PSBeDRyZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders.web_base import WebBaseLoader\n",
        "\n",
        "url = \"https://dcc.ufmg.br/\"\n",
        "loader = WebBaseLoader(url)\n",
        "doc_url = loader.load()\n",
        "\n",
        "print(f'Número de páginas: {len(doc_url)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTys1Op9DQoX",
        "outputId": "abaa0348-b289-40ca-f284-9b38e483f930"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_community.utils.user_agent:USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de páginas: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2. Dividir\n",
        "\n",
        "Vamos testar algumas formar de dividir um documento."
      ],
      "metadata": {
        "id": "2iUWpufOENRH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texto = \"\"\"\n",
        "Modelos de Linguagem de Grande Escala (LLMs, do inglês Large Language Models)\n",
        "são algoritmos de inteligência artificial treinados com enormes volumes de texto para compreender,\n",
        "gerar e interagir com linguagem natural. Eles utilizam arquiteturas baseadas em transformers\n",
        "para captar padrões complexos de uso da linguagem, permitindo aplicações como chatbots,\n",
        "tradutores automáticos, resumo de textos, geração de código e muito mais.\n",
        "Seu poder vem da combinação entre o tamanho dos dados usados no treinamento e a escala dos parâmetros do modelo,\n",
        "o que os torna capazes de realizar tarefas diversas com pouca ou nenhuma adaptação adicional.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "jrDqSNFaFZag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitters import CharacterTextSplitter\n",
        "\n",
        "# ✅ CharacterTextSplitter: use quando você quer controle bruto e rápido sobre o tamanho de strings,\n",
        "# sem se importar com a integridade semântica.\n",
        "\n",
        "char_split = CharacterTextSplitter(\n",
        "    chunk_size=50,   # Tamanho máximo (em número de caracteres) de cada chunk gerado.\n",
        "    chunk_overlap=10, # Número de caracteres que se repetem entre dois chunks consecutivos. Isso é importante para manter o contexto contínuo: o fim de um chunk é repetido no início do próximo.\n",
        "    separator=\"\"\n",
        ")\n",
        "\n",
        "split = char_split.split_text(texto)\n",
        "split"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWUQ3eIRFr1H",
        "outputId": "0f1b8310-8278-467a-b520-c9f94fed653b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Modelos de Linguagem de Grande Escala (LLMs, do i',\n",
              " 'LLMs, do inglês Large Language Models) \\nsão algori',\n",
              " 'são algoritmos de inteligência artificial treinado',\n",
              " 'l treinados com enormes volumes de texto para comp',\n",
              " 'para compreender, \\ngerar e interagir com linguage',\n",
              " 'm linguagem natural. Eles utilizam arquiteturas ba',\n",
              " 'teturas baseadas em transformers \\npara captar padr',\n",
              " 'aptar padrões complexos de uso da linguagem, permi',\n",
              " 'gem, permitindo aplicações como chatbots, \\ntraduto',\n",
              " ', \\ntradutores automáticos, resumo de textos, geraç',\n",
              " 'tos, geração de código e muito mais. \\nSeu poder ve',\n",
              " 'u poder vem da combinação entre o tamanho dos dado',\n",
              " 'o dos dados usados no treinamento e a escala dos p',\n",
              " 'cala dos parâmetros do modelo,\\no que os torna capa',\n",
              " 'torna capazes de realizar tarefas diversas com pou',\n",
              " 'as com pouca ou nenhuma adaptação adicional.']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "# ✅ RecursiveCharacterTextSplitter: é o splitter recomendado para documentos com estrutura de linguagem natural,\n",
        "# pois tenta manter o máximo de contexto relevante por chunk.\n",
        "\n",
        "char_split = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=50,\n",
        "    chunk_overlap=10,\n",
        "    separators=[\"\\n\\n\",\"\\n\", \" \", \"\"] # lista de separadores\n",
        ")\n",
        "\n",
        "split = char_split.split_text(texto)\n",
        "split"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqhaDbMlH2i4",
        "outputId": "091827e1-836e-47f7-d39d-65e5f1475fc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Modelos de Linguagem de Grande Escala (LLMs, do',\n",
              " '(LLMs, do inglês Large Language Models)',\n",
              " 'são algoritmos de inteligência artificial',\n",
              " 'treinados com enormes volumes de texto para',\n",
              " 'para compreender,',\n",
              " 'gerar e interagir com linguagem natural. Eles',\n",
              " 'Eles utilizam arquiteturas baseadas em',\n",
              " 'em transformers',\n",
              " 'para captar padrões complexos de uso da',\n",
              " 'de uso da linguagem, permitindo aplicações como',\n",
              " 'como chatbots,',\n",
              " 'tradutores automáticos, resumo de textos, geração',\n",
              " 'geração de código e muito mais.',\n",
              " 'Seu poder vem da combinação entre o tamanho dos',\n",
              " 'dos dados usados no treinamento e a escala dos',\n",
              " 'dos parâmetros do modelo,',\n",
              " 'o que os torna capazes de realizar tarefas',\n",
              " 'tarefas diversas com pouca ou nenhuma adaptação',\n",
              " 'adaptação adicional.']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "id": "XsAQsin0IpCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitters import TokenTextSplitter\n",
        "\n",
        "# ✅ TokenTextSplitter: use quando você precisa controlar exatamente quantos tokens serão enviados para o modelo,\n",
        "# por exemplo, para evitar passar do limite de contexto do LLM.\n",
        "\n",
        "char_split = TokenTextSplitter(\n",
        "    chunk_size=50,\n",
        "    chunk_overlap=10\n",
        ")\n",
        "\n",
        "split = char_split.split_text(texto)\n",
        "split"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WY4uPJvtIVdD",
        "outputId": "39ce3326-3717-4f71-9abc-7f89149b03bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\nModelos de Linguagem de Grande Escala (LLMs, do inglês Large Language Models) \\nsão algoritmos de inteligência artificial treinados com enormes volumes de texto',\n",
              " ' treinados com enormes volumes de texto para compreender, \\ngerar e interagir com linguagem natural. Eles utilizam arquiteturas baseadas em transformers \\npara captar pad',\n",
              " ' em transformers \\npara captar padrões complexos de uso da linguagem, permitindo aplicações como chatbots, \\ntradutores automáticos,',\n",
              " '\\ntradutores automáticos, resumo de textos, geração de código e muito mais. \\nSeu poder vem da combinação entre o taman',\n",
              " ' da combinação entre o tamanho dos dados usados no treinamento e a escala dos parâmetros do modelo,\\no que os torna capazes de realizar tarefas',\n",
              " ' capazes de realizar tarefas diversas com pouca ou nenhuma adaptação adicional.\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui, vamos dividir o documento PDF carregado anteriormente:"
      ],
      "metadata": {
        "id": "hq0R_AIwRocr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "char_split = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=500,\n",
        "    chunk_overlap=0,\n",
        "    separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"]\n",
        ")\n",
        "\n",
        "split_pdf = char_split.split_documents(doc_pdf)"
      ],
      "metadata": {
        "id": "3UI-OYS7Rsz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3. Armazenar\n",
        "\n",
        "Primeiro vamos trabalhar com os embeddings.\n",
        "\n",
        "Embeddings criam uma representação vetorial de um trecho de texto. Isso é útil porque nos permite pensar no texto no espaço vetorial e realizar ações como busca semântica, na qual procuramos trechos de texto mais semelhantes no espaço vetorial.\n",
        "\n",
        "A classe Embeddings é uma classe projetada para interagir com embedding models.\n",
        "\n",
        "#### 💸 Modelos de Embeddings da DeepInfra (ordenados por preço)\n",
        "\n",
        "| Modelo                                                                 | Preço (Mtoken) |\n",
        "|------------------------------------------------------------------------|------------------|\n",
        "| [BAAI/bge-base-en-v1.5](https://deepinfra.com/models/BAAI/bge-base-en-v1.5)                         | 0.005           |\n",
        "| [intfloat/e5-base-v2](https://deepinfra.com/models/intfloat/e5-base-v2)                             | 0.005           |\n",
        "| [thenlper/gte-base](https://deepinfra.com/models/thenlper/gte-base)                                 | 0.005           |\n",
        "| [sentence-transformers/all-MiniLM-L6-v2](https://deepinfra.com/models/sentence-transformers/all-MiniLM-L6-v2) | 0.005           |\n",
        "| [sentence-transformers/all-MiniLM-L12-v2](https://deepinfra.com/models/sentence-transformers/all-MiniLM-L12-v2) | 0.005           |\n",
        "| [sentence-transformers/all-mpnet-base-v2](https://deepinfra.com/models/sentence-transformers/all-mpnet-base-v2) | 0.005           |\n",
        "| [sentence-transformers/clip-ViT-B-32](https://deepinfra.com/models/sentence-transformers/clip-ViT-B-32) | 0.005           |\n",
        "| [sentence-transformers/clip-ViT-B-32-multilingual-v1](https://deepinfra.com/models/sentence-transformers/clip-ViT-B-32-multilingual-v1) | 0.005           |\n",
        "| [sentence-transformers/paraphrase-MiniLM-L6-v2](https://deepinfra.com/models/sentence-transformers/paraphrase-MiniLM-L6-v2) | 0.005           |\n",
        "| [shibing624/text2vec-base-chinese](https://deepinfra.com/models/shibing624/text2vec-base-chinese) | 0.005           |\n",
        "| [sentence-transformers/multi-qa-mpnet-base-dot-v1](https://deepinfra.com/models/sentence-transformers/multi-qa-mpnet-base-dot-v1) | 0.005           |\n",
        "| [BAAI/bge-large-en-v1.5](https://deepinfra.com/models/BAAI/bge-large-en-v1.5)                       | 0.010           |\n",
        "| [intfloat/e5-large-v2](https://deepinfra.com/models/intfloat/e5-large-v2)                           | 0.010           |\n",
        "| [thenlper/gte-large](https://deepinfra.com/models/thenlper/gte-large)                               | 0.010           |\n",
        "| [BAAI/bge-en-icl](https://deepinfra.com/models/BAAI/bge-en-icl)                                     | 0.010           |\n",
        "| [BAAI/bge-m3](https://deepinfra.com/models/BAAI/bge-m3)                                              | 0.100           |\n"
      ],
      "metadata": {
        "id": "wyJ9ysJ1JK0_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.embeddings import DeepInfraEmbeddings\n",
        "\n",
        "emb_model = DeepInfraEmbeddings(model_id=\"BAAI/bge-base-en-v1.5\")"
      ],
      "metadata": {
        "id": "JPX2SRDGXnIK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora vamos utilizar o banco de dados Chroma (vector store) para armazenar nossos embeddings e realizar pesquisas de similaridade."
      ],
      "metadata": {
        "id": "UzSR_SQ4f5Eg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --quiet  sqlite-vec"
      ],
      "metadata": {
        "id": "NwP_mPDXka0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criando uma lista dos documentos que foram divididos para inserir no banco de dados\n",
        "textos = []\n",
        "metadados = []\n",
        "\n",
        "for item in split_pdf:\n",
        "    textos.append(item.page_content)\n",
        "    metadados.append(item.metadata)"
      ],
      "metadata": {
        "id": "CoznfNQrr72i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.vectorstores import SQLiteVec\n",
        "\n",
        "vector_store = SQLiteVec.from_texts(\n",
        "    texts=textos,\n",
        "    metadatas=metadados,\n",
        "    embedding=emb_model,\n",
        "    table=\"tabela_vetorial\",\n",
        "    db_file=\"sqlite-vec.db\",\n",
        ")"
      ],
      "metadata": {
        "id": "Qmi7VLWVgeXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Abrindo o banco de dados\n",
        "vector_store = SQLiteVec(\n",
        "    connection=None,\n",
        "    embedding=emb_model,\n",
        "    table=\"tabela_vetorial\",\n",
        "    db_file=\"sqlite-vec.db\",\n",
        ")"
      ],
      "metadata": {
        "id": "x2wXzQDXrS6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pergunta = \"criança\"\n",
        "\n",
        "docs = vector_store.similarity_search(pergunta, k=10)   # Número de documentos similares que deve ser retornado\n",
        "print(f\"Número de documentos retornados: {len(docs)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iV6XXc-l5BW",
        "outputId": "8fcd2280-3efe-40db-a389-24f924414017"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de documentos retornados: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for doc in docs:   # Visualização dos documentos retornados\n",
        "    print(doc.page_content)\n",
        "    print(f\"==== {doc.metadata}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6kbL5odvmn4X",
        "outputId": "3688f09a-0f57-4b37-f496-93a9aa19f334"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gestantes, de forma transvers al, integral e intersetorial com as demais linhas de cuidado \n",
            "direcionadas à mulher e à criança. (Parágrafo acrescido pela Lei nº 13.257, de 8/3/2016) \n",
            "§ 3 º A atenção odontológica à criança terá função educativa protetiva e será prestada, \n",
            "inicialmente, antes de o bebê nascer, por meio de aconselhamento pré -natal, e, posteriormente, no\n",
            "==== {'producer': 'Microsoft® Word 2010', 'creator': 'Microsoft® Word 2010', 'creationdate': '2017-04-25T15:19:20-03:00', 'title': 'LEI Nº 8', 'author': 'p_6140', 'moddate': '2017-04-25T15:19:20-03:00', 'source': 'https://www2.camara.leg.br/legin/fed/lei/1990/lei-8069-13-julho-1990-372211-normaatualizada-pl.pdf', 'total_pages': 72, 'page': 3, 'page_label': '4'}\n",
            "\n",
            "gestantes, de forma transvers al, integral e intersetorial com as demais linhas de cuidado \n",
            "direcionadas à mulher e à criança. (Parágrafo acrescido pela Lei nº 13.257, de 8/3/2016) \n",
            "§ 3 º A atenção odontológica à criança terá função educativa protetiva e será prestada, \n",
            "inicialmente, antes de o bebê nascer, por meio de aconselhamento pré -natal, e, posteriormente, no\n",
            "==== {'producer': 'Microsoft® Word 2010', 'creator': 'Microsoft® Word 2010', 'creationdate': '2017-04-25T15:19:20-03:00', 'title': 'LEI Nº 8', 'author': 'p_6140', 'moddate': '2017-04-25T15:19:20-03:00', 'source': 'https://www2.camara.leg.br/legin/fed/lei/1990/lei-8069-13-julho-1990-372211-normaatualizada-pl.pdf', 'total_pages': 72, 'page': 3, 'page_label': '4'}\n",
            "\n",
            "criança e do adolescente para o desenvolvimento das competências necessárias  à prevenção, à\n",
            "==== {'producer': 'Microsoft® Word 2010', 'creator': 'Microsoft® Word 2010', 'creationdate': '2017-04-25T15:19:20-03:00', 'title': 'LEI Nº 8', 'author': 'p_6140', 'moddate': '2017-04-25T15:19:20-03:00', 'source': 'https://www2.camara.leg.br/legin/fed/lei/1990/lei-8069-13-julho-1990-372211-normaatualizada-pl.pdf', 'total_pages': 72, 'page': 19, 'page_label': '20'}\n",
            "\n",
            "criança e do adolescente para o desenvolvimento das competências necessárias  à prevenção, à\n",
            "==== {'producer': 'Microsoft® Word 2010', 'creator': 'Microsoft® Word 2010', 'creationdate': '2017-04-25T15:19:20-03:00', 'title': 'LEI Nº 8', 'author': 'p_6140', 'moddate': '2017-04-25T15:19:20-03:00', 'source': 'https://www2.camara.leg.br/legin/fed/lei/1990/lei-8069-13-julho-1990-372211-normaatualizada-pl.pdf', 'total_pages': 72, 'page': 19, 'page_label': '20'}\n",
            "\n",
            "Art. 2º Considera -se criança, para os efeitos desta Lei, a pessoa até doze anos de \n",
            "idade incompletos, e adolescente aquela entre doze e dezoito anos de idade.  \n",
            "Parágrafo único. Nos casos expressos em lei, aplica -se excepcionalmente este \n",
            "Estatuto às pessoas entre dezoito e vinte e um anos de idade.  \n",
            " \n",
            "Art. 3º A criança e o adolescente gozam  de todos os direitos fundamentais inerentes à \n",
            "pessoa humana, sem prejuízo da proteção integral de que trata esta Lei, assegurando-se-lhes, por\n",
            "==== {'producer': 'Microsoft® Word 2010', 'creator': 'Microsoft® Word 2010', 'creationdate': '2017-04-25T15:19:20-03:00', 'title': 'LEI Nº 8', 'author': 'p_6140', 'moddate': '2017-04-25T15:19:20-03:00', 'source': 'https://www2.camara.leg.br/legin/fed/lei/1990/lei-8069-13-julho-1990-372211-normaatualizada-pl.pdf', 'total_pages': 72, 'page': 0, 'page_label': '1'}\n",
            "\n",
            "Art. 2º Considera -se criança, para os efeitos desta Lei, a pessoa até doze anos de \n",
            "idade incompletos, e adolescente aquela entre doze e dezoito anos de idade.  \n",
            "Parágrafo único. Nos casos expressos em lei, aplica -se excepcionalmente este \n",
            "Estatuto às pessoas entre dezoito e vinte e um anos de idade.  \n",
            " \n",
            "Art. 3º A criança e o adolescente gozam  de todos os direitos fundamentais inerentes à \n",
            "pessoa humana, sem prejuízo da proteção integral de que trata esta Lei, assegurando-se-lhes, por\n",
            "==== {'producer': 'Microsoft® Word 2010', 'creator': 'Microsoft® Word 2010', 'creationdate': '2017-04-25T15:19:20-03:00', 'title': 'LEI Nº 8', 'author': 'p_6140', 'moddate': '2017-04-25T15:19:20-03:00', 'source': 'https://www2.camara.leg.br/legin/fed/lei/1990/lei-8069-13-julho-1990-372211-normaatualizada-pl.pdf', 'total_pages': 72, 'page': 0, 'page_label': '1'}\n",
            "\n",
            "§ 6 º A gestante e a parturiente têm direito a 1 (um) acompanhante de sua preferência \n",
            "durante o período do pré -natal, do trabalho de parto e do pós -parto imediato. (Parágrafo \n",
            "acrescido pela Lei nº 13.257, de 8/3/2016) \n",
            "§ 7 º A gestante deverá receber orientação sobre aleitamento materno, alimentação \n",
            "complementar saudável e crescimento e desenvolvimento infantil, bem como sobre formas de \n",
            "favorecer a cri ação de vínculos afetivos e de estimular o desenvolvimento integral da criança.\n",
            "==== {'producer': 'Microsoft® Word 2010', 'creator': 'Microsoft® Word 2010', 'creationdate': '2017-04-25T15:19:20-03:00', 'title': 'LEI Nº 8', 'author': 'p_6140', 'moddate': '2017-04-25T15:19:20-03:00', 'source': 'https://www2.camara.leg.br/legin/fed/lei/1990/lei-8069-13-julho-1990-372211-normaatualizada-pl.pdf', 'total_pages': 72, 'page': 2, 'page_label': '3'}\n",
            "\n",
            "§ 6 º A gestante e a parturiente têm direito a 1 (um) acompanhante de sua preferência \n",
            "durante o período do pré -natal, do trabalho de parto e do pós -parto imediato. (Parágrafo \n",
            "acrescido pela Lei nº 13.257, de 8/3/2016) \n",
            "§ 7 º A gestante deverá receber orientação sobre aleitamento materno, alimentação \n",
            "complementar saudável e crescimento e desenvolvimento infantil, bem como sobre formas de \n",
            "favorecer a cri ação de vínculos afetivos e de estimular o desenvolvimento integral da criança.\n",
            "==== {'producer': 'Microsoft® Word 2010', 'creator': 'Microsoft® Word 2010', 'creationdate': '2017-04-25T15:19:20-03:00', 'title': 'LEI Nº 8', 'author': 'p_6140', 'moddate': '2017-04-25T15:19:20-03:00', 'source': 'https://www2.camara.leg.br/legin/fed/lei/1990/lei-8069-13-julho-1990-372211-normaatualizada-pl.pdf', 'total_pages': 72, 'page': 2, 'page_label': '3'}\n",
            "\n",
            "II - indicação de eventual parentesco do requer ente e de seu cônjuge, ou \n",
            "companheiro, com a criança ou adolescente, especificando se tem ou não parente vivo;  \n",
            "III - qualificação completa da criança ou adolescente e de seus pais, se conhecidos;  \n",
            "IV - indicação do cartório onde foi inscrito nascimento, a nexando, se possível, uma \n",
            "cópia da respectiva certidão;  \n",
            "V - declaração sobre a existência de bens, direitos ou rendimentos relativos à criança \n",
            "ou ao adolescente.\n",
            "==== {'producer': 'Microsoft® Word 2010', 'creator': 'Microsoft® Word 2010', 'creationdate': '2017-04-25T15:19:20-03:00', 'title': 'LEI Nº 8', 'author': 'p_6140', 'moddate': '2017-04-25T15:19:20-03:00', 'source': 'https://www2.camara.leg.br/legin/fed/lei/1990/lei-8069-13-julho-1990-372211-normaatualizada-pl.pdf', 'total_pages': 72, 'page': 45, 'page_label': '46'}\n",
            "\n",
            "II - indicação de eventual parentesco do requer ente e de seu cônjuge, ou \n",
            "companheiro, com a criança ou adolescente, especificando se tem ou não parente vivo;  \n",
            "III - qualificação completa da criança ou adolescente e de seus pais, se conhecidos;  \n",
            "IV - indicação do cartório onde foi inscrito nascimento, a nexando, se possível, uma \n",
            "cópia da respectiva certidão;  \n",
            "V - declaração sobre a existência de bens, direitos ou rendimentos relativos à criança \n",
            "ou ao adolescente.\n",
            "==== {'producer': 'Microsoft® Word 2010', 'creator': 'Microsoft® Word 2010', 'creationdate': '2017-04-25T15:19:20-03:00', 'title': 'LEI Nº 8', 'author': 'p_6140', 'moddate': '2017-04-25T15:19:20-03:00', 'source': 'https://www2.camara.leg.br/legin/fed/lei/1990/lei-8069-13-julho-1990-372211-normaatualizada-pl.pdf', 'total_pages': 72, 'page': 45, 'page_label': '46'}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###4. Recuperação"
      ],
      "metadata": {
        "id": "vRLByswrnRGD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "retriever = vector_store.as_retriever()\n",
        "\n",
        "pergunta = \"Quais pessoas podem ser consideradas crianças?\"\n",
        "\n",
        "chat_template = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"\"\"Use os contextos abaixo para responder a questão no fim.\n",
        "                Se não souber a resposta, apenas diga que não sabe, não tente inventar uma resposta.\n",
        "                Use no máximo três sentenças para manter a resposta mais simples o possível.\n",
        "                Sempre diga \"obrigado por perguntar\" no fim da resposta.\n",
        "\n",
        "                {context}\n",
        "\n",
        "                \"\"\"),\n",
        "    (\"human\", \"{pergunta}\")\n",
        "  ]\n",
        ")\n",
        "\n",
        "# BUSCA POR DOCUMENTOS SIMILARES\n",
        "\n",
        "docs = retriever.invoke(pergunta)\n",
        "\n",
        "docs_text = \" \".join(d.page_content for d in docs)  # COMBINA OS DOCUMENTOS RETORNADOS EM UMA STRING ÚNICA\n",
        "\n",
        "chat = ChatDeepInfra(model=\"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\")  #Escolhendo o modelo mais barato =)\n",
        "\n",
        "chat.invoke(chat_template.format_messages(context=docs_text, pergunta=pergunta)).content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "AmrnDikoy7qj",
        "outputId": "88791177-f275-4689-8648-7ec8b2fbc6dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'As pessoas até 12 anos podem ser consideradas crianças.\\n\\nobrigado por perguntar.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    }
  ]
}