{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GabrielVeloso077/AutoMLAgents/blob/main/LangChain_RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "<table style=\"margin: auto; background-color: white;\">\n",
        "    <tr>\n",
        "      <td style=\"background-color: white;\">\n",
        "        <img src='https://drive.google.com/uc?export=view&id=1lgflViz1uefcvVW1iI57haB4M1bKsZtp' alt=\"drawing\" width=\"200\" />\n",
        "      </td>\n",
        "      <td style=\"background-color: white;\">\n",
        "        <img src='https://drive.google.com/uc?export=view&id=1S3xpVbkzpBAG51PyuRyIioecvZiHGSap' alt=\"drawing\" width=\"200\" />\n",
        "      </td>\n",
        "      <td style=\"background-color: white;\">\n",
        "        <img src='https://drive.google.com/uc?export=view&id=1lgflViz1uefcvVW1iI57haB4M1bKsZtp' alt=\"drawing\" width=\"200\" />\n",
        "      </td>\n",
        "      <td style=\"background-color: white;\">\n",
        "        <img src='https://drive.google.com/uc?export=view&id=1S3xpVbkzpBAG51PyuRyIioecvZiHGSap' alt=\"drawing\" width=\"200\" />\n",
        "      </td>\n",
        "      <td style=\"background-color: white;\">\n",
        "        <img src='https://drive.google.com/uc?export=view&id=1lgflViz1uefcvVW1iI57haB4M1bKsZtp' alt=\"drawing\" width=\"200\" />\n",
        "      </td>\n",
        "      <td style=\"background-color: white;\">\n",
        "        <img src='https://drive.google.com/uc?export=view&id=1S3xpVbkzpBAG51PyuRyIioecvZiHGSap' alt=\"drawing\" width=\"200\" />\n",
        "      </td>\n",
        "    </tr>\n",
        "</table>\n",
        "<font face=\"Verdana\" size=1 color='#707bf8' font-family= 'Alike Angular'> *Este material foi desenvolvido como parte do Projeto de Pesquisa em Parceria com a KUNUMI S/A <font>\n"
      ],
      "metadata": {
        "id": "c-1E9xStNhZh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font face=\"Rage\" size=7 color='#707bf8'> LangChain: RAG <font>\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6EPTm1oHUAsy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Instala√ß√£o LangChain"
      ],
      "metadata": {
        "id": "B0_E0uDZp6S_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G3NwJxuco_7-"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet langchain\n",
        "!pip install --quiet langchain-community"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.chat_models import ChatDeepInfra\n",
        "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage"
      ],
      "metadata": {
        "id": "aHyvyS1ftd92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Acesso √† plataforma DeepInfra"
      ],
      "metadata": {
        "id": "fYMjBzL-hzm0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "os.environ[\"DEEPINFRA_API_TOKEN\"] = getpass(\"Digite sua chave da DeepInfra: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7SjFdoEArAAb",
        "outputId": "97883d83-3478-4d83-adda-962a6ff6c8d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Digite sua chave da DeepInfra: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Gera√ß√£o aumentada por recupera√ß√£o (RAG)\n",
        "\n",
        "Uma das aplica√ß√µes mais poderosas possibilitadas pelos LLMs s√£o os sofisticados chatbots de perguntas e respostas. S√£o aplicativos que podem responder a perguntas sobre informa√ß√µes de fontes espec√≠ficas. Esses aplicativos utilizam uma t√©cnica conhecida como Gera√ß√£o Aumentada de Recupera√ß√£o, ou RAG.\n",
        "\n",
        "Uma aplica√ß√£o RAG t√≠pica tem os seguintes passos:\n",
        "\n",
        "\n",
        "\n",
        "1. **Carregar:** Primeiro, precisamos carregar nossos dados. Isso √© feito com os Document Loaders.\n",
        "2. **Dividir:** Text splitters dividem grandes documentos em peda√ßos (chunks) menores. Isso √© √∫til tanto para indexar dados quanto para pass√°-los para um modelo, pois chunks grandes s√£o mais dif√≠ceis de pesquisar e n√£o cabem na janela de contexto finita de um modelo.\n",
        "3. **Armazenamento:** Precisamos de um lugar para armazenar e indexar nossas divis√µes, para que possam ser pesquisadas posteriormente. Isso geralmente √© feito usando um VectorStore e modelos Embeddings.\n",
        "4. **Recuperar:** Dada uma entrada do usu√°rio, as divis√µes relevantes s√£o recuperadas do armazenamento usando um Retriever.\n",
        "5. **Gerar:** Um ChatModel produz uma resposta usando um prompt que inclui a pergunta com os dados recuperados.\n",
        "\n"
      ],
      "metadata": {
        "id": "_qsaAqhmj7D5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1. Carregar\n",
        "\n",
        "Carregamento de um arquivo PDF."
      ],
      "metadata": {
        "id": "KT_R95B47nux"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pypdf"
      ],
      "metadata": {
        "id": "OXhqeUQ_RkMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders.pdf import PyPDFLoader\n",
        "\n",
        "arquivo = \"https://www2.camara.leg.br/legin/fed/lei/1990/lei-8069-13-julho-1990-372211-normaatualizada-pl.pdf\"\n",
        "loader = PyPDFLoader(arquivo)\n",
        "doc_pdf = loader.load()\n",
        "\n",
        "print(f'N√∫mero de p√°ginas do PDF: {len(doc_pdf)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wcUSAtS0KTR",
        "outputId": "725120d3-b6e2-4cd3-99f7-2c0c2f035298"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "N√∫mero de p√°ginas do PDF: 72\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Carregamento de um arquivo CSV"
      ],
      "metadata": {
        "id": "f4AA61wB_oUo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
        "\n",
        "arquivo = \"imdb_movies.csv\"  # Fa√ßa apload de um arquivo CSV para testar\n",
        "loader = CSVLoader(arquivo)\n",
        "doc_csv = loader.load()\n",
        "\n",
        "print(f'N√∫mero de linhas do CSV: {len(doc_csv)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDjLmmEX_q8t",
        "outputId": "b93f62e2-61d6-47c6-ed18-5feb5340d745"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "N√∫mero de linhas do CSV: 1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Carregamento via URL"
      ],
      "metadata": {
        "id": "1592PSBeDRyZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders.web_base import WebBaseLoader\n",
        "\n",
        "url = \"https://dcc.ufmg.br/\"\n",
        "loader = WebBaseLoader(url)\n",
        "doc_url = loader.load()\n",
        "\n",
        "print(f'N√∫mero de p√°ginas: {len(doc_url)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTys1Op9DQoX",
        "outputId": "abaa0348-b289-40ca-f284-9b38e483f930"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_community.utils.user_agent:USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "N√∫mero de p√°ginas: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2. Dividir\n",
        "\n",
        "Vamos testar algumas formar de dividir um documento."
      ],
      "metadata": {
        "id": "2iUWpufOENRH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texto = \"\"\"\n",
        "Modelos de Linguagem de Grande Escala (LLMs, do ingl√™s Large Language Models)\n",
        "s√£o algoritmos de intelig√™ncia artificial treinados com enormes volumes de texto para compreender,\n",
        "gerar e interagir com linguagem natural. Eles utilizam arquiteturas baseadas em transformers\n",
        "para captar padr√µes complexos de uso da linguagem, permitindo aplica√ß√µes como chatbots,\n",
        "tradutores autom√°ticos, resumo de textos, gera√ß√£o de c√≥digo e muito mais.\n",
        "Seu poder vem da combina√ß√£o entre o tamanho dos dados usados no treinamento e a escala dos par√¢metros do modelo,\n",
        "o que os torna capazes de realizar tarefas diversas com pouca ou nenhuma adapta√ß√£o adicional.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "jrDqSNFaFZag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitters import CharacterTextSplitter\n",
        "\n",
        "# ‚úÖ CharacterTextSplitter: use quando voc√™ quer controle bruto e r√°pido sobre o tamanho de strings,\n",
        "# sem se importar com a integridade sem√¢ntica.\n",
        "\n",
        "char_split = CharacterTextSplitter(\n",
        "    chunk_size=50,   # Tamanho m√°ximo (em n√∫mero de caracteres) de cada chunk gerado.\n",
        "    chunk_overlap=10, # N√∫mero de caracteres que se repetem entre dois chunks consecutivos. Isso √© importante para manter o contexto cont√≠nuo: o fim de um chunk √© repetido no in√≠cio do pr√≥ximo.\n",
        "    separator=\"\"\n",
        ")\n",
        "\n",
        "split = char_split.split_text(texto)\n",
        "split"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWUQ3eIRFr1H",
        "outputId": "0f1b8310-8278-467a-b520-c9f94fed653b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Modelos de Linguagem de Grande Escala (LLMs, do i',\n",
              " 'LLMs, do ingl√™s Large Language Models) \\ns√£o algori',\n",
              " 's√£o algoritmos de intelig√™ncia artificial treinado',\n",
              " 'l treinados com enormes volumes de texto para comp',\n",
              " 'para compreender, \\ngerar e interagir com linguage',\n",
              " 'm linguagem natural. Eles utilizam arquiteturas ba',\n",
              " 'teturas baseadas em transformers \\npara captar padr',\n",
              " 'aptar padr√µes complexos de uso da linguagem, permi',\n",
              " 'gem, permitindo aplica√ß√µes como chatbots, \\ntraduto',\n",
              " ', \\ntradutores autom√°ticos, resumo de textos, gera√ß',\n",
              " 'tos, gera√ß√£o de c√≥digo e muito mais. \\nSeu poder ve',\n",
              " 'u poder vem da combina√ß√£o entre o tamanho dos dado',\n",
              " 'o dos dados usados no treinamento e a escala dos p',\n",
              " 'cala dos par√¢metros do modelo,\\no que os torna capa',\n",
              " 'torna capazes de realizar tarefas diversas com pou',\n",
              " 'as com pouca ou nenhuma adapta√ß√£o adicional.']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "# ‚úÖ RecursiveCharacterTextSplitter: √© o splitter recomendado para documentos com estrutura de linguagem natural,\n",
        "# pois tenta manter o m√°ximo de contexto relevante por chunk.\n",
        "\n",
        "char_split = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=50,\n",
        "    chunk_overlap=10,\n",
        "    separators=[\"\\n\\n\",\"\\n\", \" \", \"\"] # lista de separadores\n",
        ")\n",
        "\n",
        "split = char_split.split_text(texto)\n",
        "split"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqhaDbMlH2i4",
        "outputId": "091827e1-836e-47f7-d39d-65e5f1475fc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Modelos de Linguagem de Grande Escala (LLMs, do',\n",
              " '(LLMs, do ingl√™s Large Language Models)',\n",
              " 's√£o algoritmos de intelig√™ncia artificial',\n",
              " 'treinados com enormes volumes de texto para',\n",
              " 'para compreender,',\n",
              " 'gerar e interagir com linguagem natural. Eles',\n",
              " 'Eles utilizam arquiteturas baseadas em',\n",
              " 'em transformers',\n",
              " 'para captar padr√µes complexos de uso da',\n",
              " 'de uso da linguagem, permitindo aplica√ß√µes como',\n",
              " 'como chatbots,',\n",
              " 'tradutores autom√°ticos, resumo de textos, gera√ß√£o',\n",
              " 'gera√ß√£o de c√≥digo e muito mais.',\n",
              " 'Seu poder vem da combina√ß√£o entre o tamanho dos',\n",
              " 'dos dados usados no treinamento e a escala dos',\n",
              " 'dos par√¢metros do modelo,',\n",
              " 'o que os torna capazes de realizar tarefas',\n",
              " 'tarefas diversas com pouca ou nenhuma adapta√ß√£o',\n",
              " 'adapta√ß√£o adicional.']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "id": "XsAQsin0IpCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitters import TokenTextSplitter\n",
        "\n",
        "# ‚úÖ TokenTextSplitter: use quando voc√™ precisa controlar exatamente quantos tokens ser√£o enviados para o modelo,\n",
        "# por exemplo, para evitar passar do limite de contexto do LLM.\n",
        "\n",
        "char_split = TokenTextSplitter(\n",
        "    chunk_size=50,\n",
        "    chunk_overlap=10\n",
        ")\n",
        "\n",
        "split = char_split.split_text(texto)\n",
        "split"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WY4uPJvtIVdD",
        "outputId": "39ce3326-3717-4f71-9abc-7f89149b03bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\nModelos de Linguagem de Grande Escala (LLMs, do ingl√™s Large Language Models) \\ns√£o algoritmos de intelig√™ncia artificial treinados com enormes volumes de texto',\n",
              " ' treinados com enormes volumes de texto para compreender, \\ngerar e interagir com linguagem natural. Eles utilizam arquiteturas baseadas em transformers \\npara captar pad',\n",
              " ' em transformers \\npara captar padr√µes complexos de uso da linguagem, permitindo aplica√ß√µes como chatbots, \\ntradutores autom√°ticos,',\n",
              " '\\ntradutores autom√°ticos, resumo de textos, gera√ß√£o de c√≥digo e muito mais. \\nSeu poder vem da combina√ß√£o entre o taman',\n",
              " ' da combina√ß√£o entre o tamanho dos dados usados no treinamento e a escala dos par√¢metros do modelo,\\no que os torna capazes de realizar tarefas',\n",
              " ' capazes de realizar tarefas diversas com pouca ou nenhuma adapta√ß√£o adicional.\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui, vamos dividir o documento PDF carregado anteriormente:"
      ],
      "metadata": {
        "id": "hq0R_AIwRocr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "char_split = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=500,\n",
        "    chunk_overlap=0,\n",
        "    separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"]\n",
        ")\n",
        "\n",
        "split_pdf = char_split.split_documents(doc_pdf)"
      ],
      "metadata": {
        "id": "3UI-OYS7Rsz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3. Armazenar\n",
        "\n",
        "Primeiro vamos trabalhar com os embeddings.\n",
        "\n",
        "Embeddings criam uma representa√ß√£o vetorial de um trecho de texto. Isso √© √∫til porque nos permite pensar no texto no espa√ßo vetorial e realizar a√ß√µes como busca sem√¢ntica, na qual procuramos trechos de texto mais semelhantes no espa√ßo vetorial.\n",
        "\n",
        "A classe Embeddings √© uma classe projetada para interagir com embedding models.\n",
        "\n",
        "#### üí∏ Modelos de Embeddings da DeepInfra (ordenados por pre√ßo)\n",
        "\n",
        "| Modelo                                                                 | Pre√ßo (Mtoken) |\n",
        "|------------------------------------------------------------------------|------------------|\n",
        "| [BAAI/bge-base-en-v1.5](https://deepinfra.com/models/BAAI/bge-base-en-v1.5)                         | 0.005           |\n",
        "| [intfloat/e5-base-v2](https://deepinfra.com/models/intfloat/e5-base-v2)                             | 0.005           |\n",
        "| [thenlper/gte-base](https://deepinfra.com/models/thenlper/gte-base)                                 | 0.005           |\n",
        "| [sentence-transformers/all-MiniLM-L6-v2](https://deepinfra.com/models/sentence-transformers/all-MiniLM-L6-v2) | 0.005           |\n",
        "| [sentence-transformers/all-MiniLM-L12-v2](https://deepinfra.com/models/sentence-transformers/all-MiniLM-L12-v2) | 0.005           |\n",
        "| [sentence-transformers/all-mpnet-base-v2](https://deepinfra.com/models/sentence-transformers/all-mpnet-base-v2) | 0.005           |\n",
        "| [sentence-transformers/clip-ViT-B-32](https://deepinfra.com/models/sentence-transformers/clip-ViT-B-32) | 0.005           |\n",
        "| [sentence-transformers/clip-ViT-B-32-multilingual-v1](https://deepinfra.com/models/sentence-transformers/clip-ViT-B-32-multilingual-v1) | 0.005           |\n",
        "| [sentence-transformers/paraphrase-MiniLM-L6-v2](https://deepinfra.com/models/sentence-transformers/paraphrase-MiniLM-L6-v2) | 0.005           |\n",
        "| [shibing624/text2vec-base-chinese](https://deepinfra.com/models/shibing624/text2vec-base-chinese) | 0.005           |\n",
        "| [sentence-transformers/multi-qa-mpnet-base-dot-v1](https://deepinfra.com/models/sentence-transformers/multi-qa-mpnet-base-dot-v1) | 0.005           |\n",
        "| [BAAI/bge-large-en-v1.5](https://deepinfra.com/models/BAAI/bge-large-en-v1.5)                       | 0.010           |\n",
        "| [intfloat/e5-large-v2](https://deepinfra.com/models/intfloat/e5-large-v2)                           | 0.010           |\n",
        "| [thenlper/gte-large](https://deepinfra.com/models/thenlper/gte-large)                               | 0.010           |\n",
        "| [BAAI/bge-en-icl](https://deepinfra.com/models/BAAI/bge-en-icl)                                     | 0.010           |\n",
        "| [BAAI/bge-m3](https://deepinfra.com/models/BAAI/bge-m3)                                              | 0.100           |\n"
      ],
      "metadata": {
        "id": "wyJ9ysJ1JK0_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.embeddings import DeepInfraEmbeddings\n",
        "\n",
        "emb_model = DeepInfraEmbeddings(model_id=\"BAAI/bge-base-en-v1.5\")"
      ],
      "metadata": {
        "id": "JPX2SRDGXnIK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora vamos utilizar o banco de dados Chroma (vector store) para armazenar nossos embeddings e realizar pesquisas de similaridade."
      ],
      "metadata": {
        "id": "UzSR_SQ4f5Eg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --quiet  sqlite-vec"
      ],
      "metadata": {
        "id": "NwP_mPDXka0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criando uma lista dos documentos que foram divididos para inserir no banco de dados\n",
        "textos = []\n",
        "metadados = []\n",
        "\n",
        "for item in split_pdf:\n",
        "    textos.append(item.page_content)\n",
        "    metadados.append(item.metadata)"
      ],
      "metadata": {
        "id": "CoznfNQrr72i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.vectorstores import SQLiteVec\n",
        "\n",
        "vector_store = SQLiteVec.from_texts(\n",
        "    texts=textos,\n",
        "    metadatas=metadados,\n",
        "    embedding=emb_model,\n",
        "    table=\"tabela_vetorial\",\n",
        "    db_file=\"sqlite-vec.db\",\n",
        ")"
      ],
      "metadata": {
        "id": "Qmi7VLWVgeXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Abrindo o banco de dados\n",
        "vector_store = SQLiteVec(\n",
        "    connection=None,\n",
        "    embedding=emb_model,\n",
        "    table=\"tabela_vetorial\",\n",
        "    db_file=\"sqlite-vec.db\",\n",
        ")"
      ],
      "metadata": {
        "id": "x2wXzQDXrS6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pergunta = \"crian√ßa\"\n",
        "\n",
        "docs = vector_store.similarity_search(pergunta, k=10)   # N√∫mero de documentos similares que deve ser retornado\n",
        "print(f\"N√∫mero de documentos retornados: {len(docs)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iV6XXc-l5BW",
        "outputId": "8fcd2280-3efe-40db-a389-24f924414017"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "N√∫mero de documentos retornados: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for doc in docs:   # Visualiza√ß√£o dos documentos retornados\n",
        "    print(doc.page_content)\n",
        "    print(f\"==== {doc.metadata}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6kbL5odvmn4X",
        "outputId": "3688f09a-0f57-4b37-f496-93a9aa19f334"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gestantes, de forma transvers al, integral e intersetorial com as demais linhas de cuidado \n",
            "direcionadas √† mulher e √† crian√ßa. (Par√°grafo acrescido pela Lei n¬∫ 13.257, de 8/3/2016) \n",
            "¬ß 3 ¬∫ A aten√ß√£o odontol√≥gica √† crian√ßa ter√° fun√ß√£o educativa protetiva e ser√° prestada, \n",
            "inicialmente, antes de o beb√™ nascer, por meio de aconselhamento pr√© -natal, e, posteriormente, no\n",
            "==== {'producer': 'Microsoft¬Æ Word 2010', 'creator': 'Microsoft¬Æ Word 2010', 'creationdate': '2017-04-25T15:19:20-03:00', 'title': 'LEI N¬∫ 8', 'author': 'p_6140', 'moddate': '2017-04-25T15:19:20-03:00', 'source': 'https://www2.camara.leg.br/legin/fed/lei/1990/lei-8069-13-julho-1990-372211-normaatualizada-pl.pdf', 'total_pages': 72, 'page': 3, 'page_label': '4'}\n",
            "\n",
            "gestantes, de forma transvers al, integral e intersetorial com as demais linhas de cuidado \n",
            "direcionadas √† mulher e √† crian√ßa. (Par√°grafo acrescido pela Lei n¬∫ 13.257, de 8/3/2016) \n",
            "¬ß 3 ¬∫ A aten√ß√£o odontol√≥gica √† crian√ßa ter√° fun√ß√£o educativa protetiva e ser√° prestada, \n",
            "inicialmente, antes de o beb√™ nascer, por meio de aconselhamento pr√© -natal, e, posteriormente, no\n",
            "==== {'producer': 'Microsoft¬Æ Word 2010', 'creator': 'Microsoft¬Æ Word 2010', 'creationdate': '2017-04-25T15:19:20-03:00', 'title': 'LEI N¬∫ 8', 'author': 'p_6140', 'moddate': '2017-04-25T15:19:20-03:00', 'source': 'https://www2.camara.leg.br/legin/fed/lei/1990/lei-8069-13-julho-1990-372211-normaatualizada-pl.pdf', 'total_pages': 72, 'page': 3, 'page_label': '4'}\n",
            "\n",
            "crian√ßa e do adolescente para o desenvolvimento das compet√™ncias necess√°rias  √† preven√ß√£o, √†\n",
            "==== {'producer': 'Microsoft¬Æ Word 2010', 'creator': 'Microsoft¬Æ Word 2010', 'creationdate': '2017-04-25T15:19:20-03:00', 'title': 'LEI N¬∫ 8', 'author': 'p_6140', 'moddate': '2017-04-25T15:19:20-03:00', 'source': 'https://www2.camara.leg.br/legin/fed/lei/1990/lei-8069-13-julho-1990-372211-normaatualizada-pl.pdf', 'total_pages': 72, 'page': 19, 'page_label': '20'}\n",
            "\n",
            "crian√ßa e do adolescente para o desenvolvimento das compet√™ncias necess√°rias  √† preven√ß√£o, √†\n",
            "==== {'producer': 'Microsoft¬Æ Word 2010', 'creator': 'Microsoft¬Æ Word 2010', 'creationdate': '2017-04-25T15:19:20-03:00', 'title': 'LEI N¬∫ 8', 'author': 'p_6140', 'moddate': '2017-04-25T15:19:20-03:00', 'source': 'https://www2.camara.leg.br/legin/fed/lei/1990/lei-8069-13-julho-1990-372211-normaatualizada-pl.pdf', 'total_pages': 72, 'page': 19, 'page_label': '20'}\n",
            "\n",
            "Art. 2¬∫ Considera -se crian√ßa, para os efeitos desta Lei, a pessoa at√© doze anos de \n",
            "idade incompletos, e adolescente aquela entre doze e dezoito anos de idade.  \n",
            "Par√°grafo √∫nico. Nos casos expressos em lei, aplica -se excepcionalmente este \n",
            "Estatuto √†s pessoas entre dezoito e vinte e um anos de idade.  \n",
            " \n",
            "Art. 3¬∫ A crian√ßa e o adolescente gozam  de todos os direitos fundamentais inerentes √† \n",
            "pessoa humana, sem preju√≠zo da prote√ß√£o integral de que trata esta Lei, assegurando-se-lhes, por\n",
            "==== {'producer': 'Microsoft¬Æ Word 2010', 'creator': 'Microsoft¬Æ Word 2010', 'creationdate': '2017-04-25T15:19:20-03:00', 'title': 'LEI N¬∫ 8', 'author': 'p_6140', 'moddate': '2017-04-25T15:19:20-03:00', 'source': 'https://www2.camara.leg.br/legin/fed/lei/1990/lei-8069-13-julho-1990-372211-normaatualizada-pl.pdf', 'total_pages': 72, 'page': 0, 'page_label': '1'}\n",
            "\n",
            "Art. 2¬∫ Considera -se crian√ßa, para os efeitos desta Lei, a pessoa at√© doze anos de \n",
            "idade incompletos, e adolescente aquela entre doze e dezoito anos de idade.  \n",
            "Par√°grafo √∫nico. Nos casos expressos em lei, aplica -se excepcionalmente este \n",
            "Estatuto √†s pessoas entre dezoito e vinte e um anos de idade.  \n",
            " \n",
            "Art. 3¬∫ A crian√ßa e o adolescente gozam  de todos os direitos fundamentais inerentes √† \n",
            "pessoa humana, sem preju√≠zo da prote√ß√£o integral de que trata esta Lei, assegurando-se-lhes, por\n",
            "==== {'producer': 'Microsoft¬Æ Word 2010', 'creator': 'Microsoft¬Æ Word 2010', 'creationdate': '2017-04-25T15:19:20-03:00', 'title': 'LEI N¬∫ 8', 'author': 'p_6140', 'moddate': '2017-04-25T15:19:20-03:00', 'source': 'https://www2.camara.leg.br/legin/fed/lei/1990/lei-8069-13-julho-1990-372211-normaatualizada-pl.pdf', 'total_pages': 72, 'page': 0, 'page_label': '1'}\n",
            "\n",
            "¬ß 6 ¬∫ A gestante e a parturiente t√™m direito a 1 (um) acompanhante de sua prefer√™ncia \n",
            "durante o per√≠odo do pr√© -natal, do trabalho de parto e do p√≥s -parto imediato. (Par√°grafo \n",
            "acrescido pela Lei n¬∫ 13.257, de 8/3/2016) \n",
            "¬ß 7 ¬∫ A gestante dever√° receber orienta√ß√£o sobre aleitamento materno, alimenta√ß√£o \n",
            "complementar saud√°vel e crescimento e desenvolvimento infantil, bem como sobre formas de \n",
            "favorecer a cri a√ß√£o de v√≠nculos afetivos e de estimular o desenvolvimento integral da crian√ßa.\n",
            "==== {'producer': 'Microsoft¬Æ Word 2010', 'creator': 'Microsoft¬Æ Word 2010', 'creationdate': '2017-04-25T15:19:20-03:00', 'title': 'LEI N¬∫ 8', 'author': 'p_6140', 'moddate': '2017-04-25T15:19:20-03:00', 'source': 'https://www2.camara.leg.br/legin/fed/lei/1990/lei-8069-13-julho-1990-372211-normaatualizada-pl.pdf', 'total_pages': 72, 'page': 2, 'page_label': '3'}\n",
            "\n",
            "¬ß 6 ¬∫ A gestante e a parturiente t√™m direito a 1 (um) acompanhante de sua prefer√™ncia \n",
            "durante o per√≠odo do pr√© -natal, do trabalho de parto e do p√≥s -parto imediato. (Par√°grafo \n",
            "acrescido pela Lei n¬∫ 13.257, de 8/3/2016) \n",
            "¬ß 7 ¬∫ A gestante dever√° receber orienta√ß√£o sobre aleitamento materno, alimenta√ß√£o \n",
            "complementar saud√°vel e crescimento e desenvolvimento infantil, bem como sobre formas de \n",
            "favorecer a cri a√ß√£o de v√≠nculos afetivos e de estimular o desenvolvimento integral da crian√ßa.\n",
            "==== {'producer': 'Microsoft¬Æ Word 2010', 'creator': 'Microsoft¬Æ Word 2010', 'creationdate': '2017-04-25T15:19:20-03:00', 'title': 'LEI N¬∫ 8', 'author': 'p_6140', 'moddate': '2017-04-25T15:19:20-03:00', 'source': 'https://www2.camara.leg.br/legin/fed/lei/1990/lei-8069-13-julho-1990-372211-normaatualizada-pl.pdf', 'total_pages': 72, 'page': 2, 'page_label': '3'}\n",
            "\n",
            "II - indica√ß√£o de eventual parentesco do requer ente e de seu c√¥njuge, ou \n",
            "companheiro, com a crian√ßa ou adolescente, especificando se tem ou n√£o parente vivo;  \n",
            "III - qualifica√ß√£o completa da crian√ßa ou adolescente e de seus pais, se conhecidos;  \n",
            "IV - indica√ß√£o do cart√≥rio onde foi inscrito nascimento, a nexando, se poss√≠vel, uma \n",
            "c√≥pia da respectiva certid√£o;  \n",
            "V - declara√ß√£o sobre a exist√™ncia de bens, direitos ou rendimentos relativos √† crian√ßa \n",
            "ou ao adolescente.\n",
            "==== {'producer': 'Microsoft¬Æ Word 2010', 'creator': 'Microsoft¬Æ Word 2010', 'creationdate': '2017-04-25T15:19:20-03:00', 'title': 'LEI N¬∫ 8', 'author': 'p_6140', 'moddate': '2017-04-25T15:19:20-03:00', 'source': 'https://www2.camara.leg.br/legin/fed/lei/1990/lei-8069-13-julho-1990-372211-normaatualizada-pl.pdf', 'total_pages': 72, 'page': 45, 'page_label': '46'}\n",
            "\n",
            "II - indica√ß√£o de eventual parentesco do requer ente e de seu c√¥njuge, ou \n",
            "companheiro, com a crian√ßa ou adolescente, especificando se tem ou n√£o parente vivo;  \n",
            "III - qualifica√ß√£o completa da crian√ßa ou adolescente e de seus pais, se conhecidos;  \n",
            "IV - indica√ß√£o do cart√≥rio onde foi inscrito nascimento, a nexando, se poss√≠vel, uma \n",
            "c√≥pia da respectiva certid√£o;  \n",
            "V - declara√ß√£o sobre a exist√™ncia de bens, direitos ou rendimentos relativos √† crian√ßa \n",
            "ou ao adolescente.\n",
            "==== {'producer': 'Microsoft¬Æ Word 2010', 'creator': 'Microsoft¬Æ Word 2010', 'creationdate': '2017-04-25T15:19:20-03:00', 'title': 'LEI N¬∫ 8', 'author': 'p_6140', 'moddate': '2017-04-25T15:19:20-03:00', 'source': 'https://www2.camara.leg.br/legin/fed/lei/1990/lei-8069-13-julho-1990-372211-normaatualizada-pl.pdf', 'total_pages': 72, 'page': 45, 'page_label': '46'}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###4. Recupera√ß√£o"
      ],
      "metadata": {
        "id": "vRLByswrnRGD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "retriever = vector_store.as_retriever()\n",
        "\n",
        "pergunta = \"Quais pessoas podem ser consideradas crian√ßas?\"\n",
        "\n",
        "chat_template = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"\"\"Use os contextos abaixo para responder a quest√£o no fim.\n",
        "                Se n√£o souber a resposta, apenas diga que n√£o sabe, n√£o tente inventar uma resposta.\n",
        "                Use no m√°ximo tr√™s senten√ßas para manter a resposta mais simples o poss√≠vel.\n",
        "                Sempre diga \"obrigado por perguntar\" no fim da resposta.\n",
        "\n",
        "                {context}\n",
        "\n",
        "                \"\"\"),\n",
        "    (\"human\", \"{pergunta}\")\n",
        "  ]\n",
        ")\n",
        "\n",
        "# BUSCA POR DOCUMENTOS SIMILARES\n",
        "\n",
        "docs = retriever.invoke(pergunta)\n",
        "\n",
        "docs_text = \" \".join(d.page_content for d in docs)  # COMBINA OS DOCUMENTOS RETORNADOS EM UMA STRING √öNICA\n",
        "\n",
        "chat = ChatDeepInfra(model=\"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\")  #Escolhendo o modelo mais barato =)\n",
        "\n",
        "chat.invoke(chat_template.format_messages(context=docs_text, pergunta=pergunta)).content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "AmrnDikoy7qj",
        "outputId": "88791177-f275-4689-8648-7ec8b2fbc6dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'As pessoas at√© 12 anos podem ser consideradas crian√ßas.\\n\\nobrigado por perguntar.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    }
  ]
}